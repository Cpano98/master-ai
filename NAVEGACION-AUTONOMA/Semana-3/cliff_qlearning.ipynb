{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Szdel_AUvoSY"
   },
   "source": [
    "# Solución de Cliff con Q-learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vPsOsbZqvknd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOQcKZeJwNLW"
   },
   "source": [
    "### Un grid de tres renglones con cuatro columnas. En cada celda se puede tomar una de cuatro acciones: norte, sur, este, oeste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6SiCYEoTwIPb"
   },
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 12\n",
    "nact = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZeYgJm2wsjm"
   },
   "source": [
    "### Parámetros de entrenamiento. Se define el número de episodios, epsilon para combinar exploración y explotación, alfa es el learning rate y gamma se usa en la función de Bellman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3WfMNktww0QN"
   },
   "outputs": [],
   "source": [
    "nepisodes = 100000\n",
    "epsilon = 0.1 # epsilon-greedy\n",
    "alpha = 0.1   # learning rate\n",
    "gamma = 0.95  # discount factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W81UsF9Fw621"
   },
   "source": [
    "### Las diferentes rewards del environment. Caer en el desfiladero otorga el peor penalti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IT_eWQokxBpV"
   },
   "outputs": [],
   "source": [
    "reward_normal = -1\n",
    "reward_cliff = -100\n",
    "reward_destination = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-Vvhis_xIbF"
   },
   "source": [
    "### Creación de los Q values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCP8bhUkxMFT",
    "outputId": "bd1d1e8e-6b40-4fb9-c3f5-3ad98a529e39"
   },
   "outputs": [],
   "source": [
    "Q = np.zeros((nrows,ncols,nact),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6vmn0j4xal8"
   },
   "source": [
    "### Función para ir al inicio del grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OypGplF8xi6i"
   },
   "outputs": [],
   "source": [
    "def go_to_start():\n",
    "    # start coordinates \n",
    "    y = nrows\n",
    "    x = 0\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su0F6YUGxnss"
   },
   "source": [
    "### Generador aleatorio de acciones. Sólo hay cuatro posibles acciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Dc_MmQXhx1Us"
   },
   "outputs": [],
   "source": [
    "def random_action():\n",
    "    # a = 0 : top/north\n",
    "    # a = 1 : right/east\n",
    "    # a = 2 : bottom/south\n",
    "    # a = 3 : left/west\n",
    "    a = np.random.randint(nact)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dP0qGsjTyP6a"
   },
   "source": [
    "### Función que calcula el nuevo estado dados el estado actual y la acción tomada por el agente. El origen, 0, 0, se encuentra en la parte superior izquierda, mientras que la parte inferior derecha marca el límite del grid, ncols-1 y nrows-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OmUyzKhTyhdu"
   },
   "outputs": [],
   "source": [
    "def move(x,y,a):\n",
    "    # state = 0: OK\n",
    "    # state = 1: reached destination\n",
    "    # state = 2: fell into cliff\n",
    "    state = 0 \n",
    "\n",
    "    if (x == 0 and y == nrows and a == 0):\n",
    "        # start location\n",
    "        x1 = x\n",
    "        y1 = y - 1 \n",
    "        return x1, y1, state  \n",
    "    elif (x == ncols-1 and y == nrows-1 and a == 2):\n",
    "        # reached destination\n",
    "        x1 = x\n",
    "        y1 = y + 1\n",
    "        state = 1\n",
    "        return x1, y1, state\n",
    "    else: \n",
    "        if (a == 0):\n",
    "            x1 = x\n",
    "            y1 = y - 1\n",
    "        elif (a == 1):\n",
    "            x1 = x + 1\n",
    "            y1 = y\n",
    "        elif (a == 2):\n",
    "            x1 = x\n",
    "            y1 = y + 1\n",
    "        elif (a == 3):\n",
    "            x1 = x - 1 \n",
    "            y1 = y\n",
    "        if (x1 < 0):\n",
    "            x1 = 0\n",
    "        if (x1 > ncols-1):\n",
    "            x1 = ncols-1\n",
    "        if (y1 < 0):\n",
    "            y1 = 0\n",
    "        if (y1 > nrows-1):\n",
    "            state = 2\n",
    "        return x1, y1, state    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpj6Rr6I0boz"
   },
   "source": [
    "### La función exploit regresa la mejor acción para maximizar el reward (greedy action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QLD8u6-L0pma"
   },
   "outputs": [],
   "source": [
    "def exploit(x,y,Q):\n",
    "    # start location, go north\n",
    "    if (x == 0 and y == nrows):\n",
    "        a = 0\n",
    "        return a \n",
    "    # destination location, go south\n",
    "    if (x == ncols-1 and y == nrows-1):\n",
    "        a = 2\n",
    "        return a\n",
    "    if (x == ncols-1 and y == nrows):\n",
    "        print(\"exploit at destination not possible \")\n",
    "        # run-time terminated\n",
    "        sys.exit()\n",
    "    # interior location\n",
    "    if (x < 0 or x > ncols-1 or y < 0 or y > nrows-1):\n",
    "        print(\"error \", x, y)\n",
    "        sys.exit()\n",
    "    a = np.argmax(Q[y,x,:]) \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Wj-w7bb00Hx"
   },
   "source": [
    "### La ecuación de Bellman actualiza la Q table con Q values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW_bU0UiLnrd"
   },
   "source": [
    "![bellman](https://drive.google.com/uc?export=view&id=1V4QTcaZ9jNoeTu0gostwmG9HATQ0kNV3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eCXfmw2r06Jx"
   },
   "outputs": [],
   "source": [
    "def bellman(x,y,a,reward,Qs1a1,Q):\n",
    "    if (y == nrows and x == 0):\n",
    "        # at start location; no Bellman update possible\n",
    "        return Q\n",
    "    if (y == nrows and x == ncols-1):\n",
    "        # at destination location; no Bellman update possible\n",
    "        return Q\n",
    "    Q[y,x,a] = Q[y,x,a] + alpha*(reward + gamma*Qs1a1 - Q[y,x,a])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HOAmR0k5xqP"
   },
   "source": [
    "### Esta función regresa la acción con el mayor Q value dado el estado indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "urMMz7NI53SP"
   },
   "outputs": [],
   "source": [
    "def max_Q(x,y,Q):\n",
    "    a = np.argmax(Q[y,x,:]) \n",
    "    return Q[y,x,a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDw2_o7_6JJb"
   },
   "source": [
    "### Función que combina las estrategias de explore y exploit usando el valor indicado de Epsilon. Si es explore, la acción es aleatoria y, si es exploit, se invoca la función exploit para maximizar el reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w8LzYBnE6vIX"
   },
   "outputs": [],
   "source": [
    "def explore_exploit(x,y,Q):\n",
    "    # if we end up at the start location, then exploit\n",
    "    if (x == 0 and y == nrows):\n",
    "        a = 0\n",
    "        return a\n",
    "    # random r compared to epsilon defines if it is explore or exploit \n",
    "    r = np.random.uniform()\n",
    "    if (r < epsilon):\n",
    "        # explore\n",
    "        a = random_action()\n",
    "    else:\n",
    "        # exploit\n",
    "        a = exploit(x,y,Q) \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpE3tgx97gEH"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_KCyHhR7hY_",
    "outputId": "7603d4b0-a15e-4783-8087-7e3b9bdd69b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode #:  0\n",
      "episode #:  1000\n",
      "episode #:  2000\n",
      "episode #:  3000\n",
      "episode #:  4000\n",
      "episode #:  5000\n",
      "episode #:  6000\n",
      "episode #:  7000\n",
      "episode #:  8000\n",
      "episode #:  9000\n",
      "episode #:  10000\n",
      "episode #:  11000\n",
      "episode #:  12000\n",
      "episode #:  13000\n",
      "episode #:  14000\n",
      "episode #:  15000\n",
      "episode #:  16000\n",
      "episode #:  17000\n",
      "episode #:  18000\n",
      "episode #:  19000\n",
      "episode #:  20000\n",
      "episode #:  21000\n",
      "episode #:  22000\n",
      "episode #:  23000\n",
      "episode #:  24000\n",
      "episode #:  25000\n",
      "episode #:  26000\n",
      "episode #:  27000\n",
      "episode #:  28000\n",
      "episode #:  29000\n",
      "episode #:  30000\n",
      "episode #:  31000\n",
      "episode #:  32000\n",
      "episode #:  33000\n",
      "episode #:  34000\n",
      "episode #:  35000\n",
      "episode #:  36000\n",
      "episode #:  37000\n",
      "episode #:  38000\n",
      "episode #:  39000\n",
      "episode #:  40000\n",
      "episode #:  41000\n",
      "episode #:  42000\n",
      "episode #:  43000\n",
      "episode #:  44000\n",
      "episode #:  45000\n",
      "episode #:  46000\n",
      "episode #:  47000\n",
      "episode #:  48000\n",
      "episode #:  49000\n",
      "episode #:  50000\n",
      "episode #:  51000\n",
      "episode #:  52000\n",
      "episode #:  53000\n",
      "episode #:  54000\n",
      "episode #:  55000\n",
      "episode #:  56000\n",
      "episode #:  57000\n",
      "episode #:  58000\n",
      "episode #:  59000\n",
      "episode #:  60000\n",
      "episode #:  61000\n",
      "episode #:  62000\n",
      "episode #:  63000\n",
      "episode #:  64000\n",
      "episode #:  65000\n",
      "episode #:  66000\n",
      "episode #:  67000\n",
      "episode #:  68000\n",
      "episode #:  69000\n",
      "episode #:  70000\n",
      "episode #:  71000\n",
      "episode #:  72000\n",
      "episode #:  73000\n",
      "episode #:  74000\n",
      "episode #:  75000\n",
      "episode #:  76000\n",
      "episode #:  77000\n",
      "episode #:  78000\n",
      "episode #:  79000\n",
      "episode #:  80000\n",
      "episode #:  81000\n",
      "episode #:  82000\n",
      "episode #:  83000\n",
      "episode #:  84000\n",
      "episode #:  85000\n",
      "episode #:  86000\n",
      "episode #:  87000\n",
      "episode #:  88000\n",
      "episode #:  89000\n",
      "episode #:  90000\n",
      "episode #:  91000\n",
      "episode #:  92000\n",
      "episode #:  93000\n",
      "episode #:  94000\n",
      "episode #:  95000\n",
      "episode #:  96000\n",
      "episode #:  97000\n",
      "episode #:  98000\n",
      "episode #:  99000\n",
      "episode #:  100000\n"
     ]
    }
   ],
   "source": [
    "for n in range(nepisodes+1):\n",
    "    if (n % 1000 == 0): \n",
    "        print(\"episode #: \", n)\n",
    "    x, y = go_to_start()\n",
    "\n",
    "    while(True):\n",
    "        a = explore_exploit(x,y,Q)\n",
    "        x1, y1, state = move(x,y,a)\n",
    "        if (state == 1):\n",
    "            reward = reward_destination\n",
    "            Qs1a1 = 0.0\n",
    "            Q = bellman(x,y,a,reward,Qs1a1,Q)\n",
    "            break \n",
    "        elif (state == 2):         \n",
    "            reward = reward_cliff\n",
    "            Qs1a1 = 0.0\n",
    "            Q = bellman(x,y,a,reward,Qs1a1,Q)\n",
    "            break\n",
    "        elif (state == 0):     \n",
    "            reward = reward_normal\n",
    "            # Q-learning\n",
    "            Qs1a1 = max_Q(x1,y1,Q)\n",
    "     \n",
    "            Q = bellman(x,y,a,reward,Qs1a1,Q)\n",
    "            x = x1\n",
    "            y = y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br6_KQmf8QbO"
   },
   "source": [
    "### Graficación de los resultados del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sMqeu4S38VjN"
   },
   "outputs": [],
   "source": [
    "for i in range(nact):\n",
    "    plt.subplot(nact,1,i+1)\n",
    "    plt.imshow(Q[:,:,i])\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    if (i == 0):\n",
    "        plt.title('Q-north')\n",
    "    elif (i == 1):\n",
    "        plt.title('Q-east')\n",
    "    elif (i == 2):\n",
    "        plt.title('Q-south')\n",
    "    elif (i == 3):\n",
    "        plt.title('Q-west')    \n",
    "    plt.savefig('Q_qlearning.png')\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs09niDQ81nu"
   },
   "source": [
    "### Path Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "uyBtRIxk83TF",
    "outputId": "b9e4112e-c030-41f1-83e6-a30b756270ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 0\n",
      "0 2 1\n",
      "1 2 1\n",
      "2 2 1\n",
      "3 2 1\n",
      "4 2 1\n",
      "5 2 1\n",
      "6 2 1\n",
      "7 2 1\n",
      "8 2 1\n",
      "9 2 1\n",
      "10 2 1\n",
      "11 2 2\n",
      "breaking  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = np.zeros((nrows,ncols,nact),dtype=np.float32)\n",
    "\n",
    "x, y = go_to_start()\n",
    "while(True):\n",
    "    a = exploit(x,y,Q) \n",
    "    print(x,y,a)\n",
    "    x1, y1, state = move(x,y,a)\n",
    "    if (state == 1 or state == 2):\n",
    "        print(\"breaking \", state)\n",
    "        break \n",
    "    elif (state == 0):     \n",
    "        x = x1\n",
    "        y = y1\n",
    "        if (x >= 0 and x <= ncols-1 and y >= 0 and y <= nrows-1):\n",
    "            path[y,x] = 100.0\n",
    "\n",
    "path = np.array(path).astype(np.uint8)\n",
    "\n",
    "plt.imshow(path)\n",
    "plt.savefig('path_sarsa.png')\n",
    "\n",
    "#print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP0nHUaYRoQB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
