{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "759SG4TyfbUn"
      },
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ue1YAKx3XDo"
      },
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ . \n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-h4drXD-X9"
      },
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY6yifxscfrx"
      },
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios. \n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "outputs": [],
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "QHUmJyjDdGNP"
      },
      "outputs": [],
      "source": [
        "# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\n",
        "\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt',        \n",
        "          mode='r',     # abrimos el archivo en modo lectura.\n",
        "          ) as f:\n",
        "    docs = f.readlines()    # separamos cada comentario por líneas\n",
        "\n",
        "f.close()  # ya que tenemos la información en la variable docs, cerramos el archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "id": "L6WzrSrodG-Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 420,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "id": "QIK1u9WS2FtS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 421,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "id": "9AMLIfQvJqNZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Wow... Loved this place.\\n',\n",
              " 'Crust is not good.\\n',\n",
              " 'Not tasty and the texture was just nasty.\\n',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n',\n",
              " 'The selection on the menu was great and so were the prices.\\n',\n",
              " 'Now I am getting angry and I want my damn pho.\\n',\n",
              " \"Honeslty it didn't taste THAT fresh.)\\n\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n',\n",
              " 'The fries were great too.\\n',\n",
              " 'A great touch.\\n']"
            ]
          },
          "execution_count": 422,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_ewoagic5jc"
      },
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-eMJa3DFCIV"
      },
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing REGEX library\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78nJMemzn5a5"
      },
      "source": [
        "*   **Pregunta 1.** \n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario. \n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "PwbYYIuZn8pE"
      },
      "outputs": [],
      "source": [
        "docs_copy = docs.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs_copy = [re.sub(r'\\n$', '', comment) for comment in docs_copy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "j-0qeh2Jn8l1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Original docs ---------\n",
            "['Wow... Loved this place.\\n', 'Crust is not good.\\n', 'Not tasty and the texture was just nasty.\\n', 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n', 'The selection on the menu was great and so were the prices.\\n', 'Now I am getting angry and I want my damn pho.\\n', \"Honeslty it didn't taste THAT fresh.)\\n\", 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n', 'The fries were great too.\\n', 'A great touch.\\n']\n",
            "\n",
            "--------- Modified docs_copy ---------\n",
            "['Wow... Loved this place.', 'Crust is not good.', 'Not tasty and the texture was just nasty.', 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.', 'The selection on the menu was great and so were the prices.', 'Now I am getting angry and I want my damn pho.', \"Honeslty it didn't taste THAT fresh.)\", 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.', 'The fries were great too.', 'A great touch.']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--------- Original docs ---------\")\n",
        "print(docs[0:10])\n",
        "print(\"\\n--------- Modified docs_copy ---------\") \n",
        "print(docs_copy[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Docs without linebreak ---------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "execution_count": 427,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n--------- Docs without linebreak ---------\") \n",
        "docs_copy[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWeKQC93ctEo"
      },
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\". \n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen. \n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "id": "0p3kMXfddICc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words ending with multiple exclamation marks: ---------\n",
            "\n",
            "Word: Firehouse!!!!!\n",
            "----- Total exclamation marks: 5\n",
            "\n",
            "Word: APPETIZERS!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: amazing!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: buffet!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: good!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: it!!!!\n",
            "----- Total exclamation marks: 4\n",
            "\n",
            "Word: DELICIOUS!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: amazing!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: shawarrrrrrma!!!!!!\n",
            "----- Total exclamation marks: 6\n",
            "\n",
            "Word: yucky!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: steak!!!!!\n",
            "----- Total exclamation marks: 5\n",
            "\n",
            "Word: delicious!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: far!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: biscuits!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: dry!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: disappointing!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: awesome!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: Up!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: FLY!!!!!!!!\n",
            "----- Total exclamation marks: 8\n",
            "\n",
            "Word: here!!!\n",
            "----- Total exclamation marks: 3\n",
            "\n",
            "Word: great!!!!!!!!!!!!!!\n",
            "----- Total exclamation marks: 14\n",
            "\n",
            "Word: packed!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: otherwise!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: amazing!!!!!!!!!!!!!!!!!!!\n",
            "----- Total exclamation marks: 19\n",
            "\n",
            "Word: style!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "Word: disappointed!!\n",
            "----- Total exclamation marks: 2\n",
            "\n",
            "\n",
            "\n",
            "--------- Total matches found: 26\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\b\\w+!{2,}'\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words ending with multiple exclamation marks: ---------\\n\")\n",
        "for match in matches:\n",
        "    exclamation_count = match.count('!')\n",
        "    print(f\"Word: {match}\\n----- Total exclamation marks: {exclamation_count}\\n\")\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s3okBqL96TT"
      },
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "yKHJkZKo_nW5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words in UPPERCASE: ---------\n",
            "THAT\n",
            "APPETIZERS\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "STEP\n",
            "FORWARD\n",
            "IN\n",
            "IT\n",
            "AGAIN\n",
            "LOVED\n",
            "AND\n",
            "REAL\n",
            "BITCHES\n",
            "NYC\n",
            "STALE\n",
            "DELICIOUS\n",
            "WORST\n",
            "EXPERIENCE\n",
            "EVER\n",
            "ALL\n",
            "BARGAIN\n",
            "TV\n",
            "NONE\n",
            "FREEZING\n",
            "AYCE\n",
            "FLAVOR\n",
            "NEVER\n",
            "BBQ\n",
            "UNREAL\n",
            "OMG\n",
            "BETTER\n",
            "BLAND\n",
            "RUDE\n",
            "INCONSIDERATE\n",
            "MANAGEMENT\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "GO\n",
            "BACK\n",
            "AND\n",
            "HAVE\n",
            "TOLD\n",
            "MANY\n",
            "PEOPLE\n",
            "WHAT\n",
            "HAD\n",
            "HAPPENED\n",
            "TOTAL\n",
            "WASTE\n",
            "OF\n",
            "TIME\n",
            "FS\n",
            "AZ\n",
            "LOVED\n",
            "CONCLUSION\n",
            "BEST\n",
            "GO\n",
            "NOW\n",
            "GC\n",
            "AVOID\n",
            "THIS\n",
            "ESTABLISHMENT\n",
            "AN\n",
            "HOUR\n",
            "NASTY\n",
            "OMG\n",
            "NO\n",
            "BEST\n",
            "THE\n",
            "OWNERS\n",
            "REALLY\n",
            "REALLY\n",
            "PERFECT\n",
            "SCREAMS\n",
            "LEGIT\n",
            "MGM\n",
            "BEST\n",
            "FLY\n",
            "FLY\n",
            "FANTASTIC\n",
            "GREAT\n",
            "OK\n",
            "WAY\n",
            "MUST\n",
            "HAVE\n",
            "OK\n",
            "OVERPRICED\n",
            "BARE\n",
            "HANDS\n",
            "WEAK\n",
            "SHOULD\n",
            "RI\n",
            "VERY\n",
            "NOT\n",
            "\n",
            "\n",
            "--------- Total matches found: 96\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\b[A-Z]{2,}+\\b' #NOTE: CONSIDERING A WORD WITH 2 OR MORE UPPERCASE LETTERS\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words in UPPERCASE: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words in UPPERCASE: ---------\n",
            "I\n",
            "I\n",
            "THAT\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "APPETIZERS\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "STEP\n",
            "FORWARD\n",
            "IN\n",
            "IT\n",
            "AGAIN\n",
            "I\n",
            "LOVED\n",
            "I\n",
            "AND\n",
            "REAL\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BITCHES\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "NYC\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "STALE\n",
            "I\n",
            "I\n",
            "DELICIOUS\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "WORST\n",
            "EXPERIENCE\n",
            "EVER\n",
            "I\n",
            "ALL\n",
            "I\n",
            "BARGAIN\n",
            "I\n",
            "TV\n",
            "NONE\n",
            "I\n",
            "M\n",
            "FREEZING\n",
            "AYCE\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "FLAVOR\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "NEVER\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BBQ\n",
            "I\n",
            "A\n",
            "I\n",
            "UNREAL\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "OMG\n",
            "I\n",
            "BETTER\n",
            "I\n",
            "I\n",
            "BLAND\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "RUDE\n",
            "INCONSIDERATE\n",
            "MANAGEMENT\n",
            "I\n",
            "I\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "GO\n",
            "BACK\n",
            "AND\n",
            "HAVE\n",
            "TOLD\n",
            "MANY\n",
            "PEOPLE\n",
            "WHAT\n",
            "HAD\n",
            "HAPPENED\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "TOTAL\n",
            "WASTE\n",
            "OF\n",
            "TIME\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "FS\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "AZ\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "LOVED\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "CONCLUSION\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BEST\n",
            "I\n",
            "GO\n",
            "NOW\n",
            "A\n",
            "I\n",
            "I\n",
            "GC\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "AVOID\n",
            "THIS\n",
            "ESTABLISHMENT\n",
            "I\n",
            "I\n",
            "I\n",
            "A\n",
            "I\n",
            "I\n",
            "AN\n",
            "HOUR\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "NASTY\n",
            "OMG\n",
            "I\n",
            "I\n",
            "NO\n",
            "I\n",
            "I\n",
            "I\n",
            "BEST\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "THE\n",
            "OWNERS\n",
            "REALLY\n",
            "REALLY\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "PERFECT\n",
            "SCREAMS\n",
            "LEGIT\n",
            "I\n",
            "MGM\n",
            "I\n",
            "I\n",
            "I\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BEST\n",
            "I\n",
            "I\n",
            "T\n",
            "A\n",
            "FLY\n",
            "A\n",
            "FLY\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "FANTASTIC\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "GREAT\n",
            "OK\n",
            "I\n",
            "I\n",
            "WAY\n",
            "I\n",
            "I\n",
            "MUST\n",
            "HAVE\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "OK\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "OVERPRICED\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BARE\n",
            "HANDS\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "WEAK\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "SHOULD\n",
            "I\n",
            "I\n",
            "I\n",
            "RI\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "VERY\n",
            "I\n",
            "I\n",
            "I\n",
            "NOT\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "\n",
            "\n",
            "--------- Total matches found: 455\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\b[A-Z]{1,}+\\b' #NOTE: CONSIDERING A WORD WITH 1 OR MORE UPPERCASE LETTERS\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words in UPPERCASE: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX8eYyDoMZma"
      },
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas. \n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "K8VuZxvTMYj6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Complete Comments in UPPERCASE: ---------\n",
            "DELICIOUS!!\n",
            "WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.\n",
            "TOTAL WASTE OF TIME.\n",
            "AVOID THIS ESTABLISHMENT!\n",
            "\n",
            "\n",
            "--------- Total matches found: 4\n"
          ]
        }
      ],
      "source": [
        "pattern = r'^[A-Z\\s.,!?]+$'\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    comment = comment.strip()\n",
        "    if re.match(pattern, comment):\n",
        "        matches.append(comment)\n",
        "\n",
        "print(\"\\n--------- Complete Comments in UPPERCASE: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1i6qv7-McmU"
      },
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "nZZ5zKUOMeGD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words with accented vowels: ---------\n",
            "fiancé\n",
            "Café\n",
            "puréed\n",
            "\n",
            "\n",
            "--------- Total matches found: 3\n"
          ]
        }
      ],
      "source": [
        "pattern = r'[a-zA-Z]*[áéíóú][a-zA-Z]*'\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words with accented vowels: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      },
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "6vhe9-Y-MhL9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Monetary amounts starting with $: ---------\n",
            "$20\n",
            "$4.00\n",
            "$17\n",
            "$3\n",
            "$35\n",
            "$7.85\n",
            "$12\n",
            "$11.99\n",
            "\n",
            "\n",
            "--------- Total matches found: 8\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\$\\d+(?:\\.\\d{2})?'\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Monetary amounts starting with $: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j-HpvhwMhq2"
      },
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "kqqyRChVMjol"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words containing 'love' variations: ---------\n",
            "Loved\n",
            "loved\n",
            "Loved\n",
            "love\n",
            "loves\n",
            "LOVED\n",
            "lovers\n",
            "love\n",
            "lovers\n",
            "Love\n",
            "loved\n",
            "loved\n",
            "love\n",
            "love\n",
            "love\n",
            "loved\n",
            "love\n",
            "loved\n",
            "Love\n",
            "LOVED\n",
            "love\n",
            "lovely\n",
            "love\n",
            "lovely\n",
            "love\n",
            "lover\n",
            "loved\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "loves\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "\n",
            "\n",
            "--------- Total matches found: 36\n"
          ]
        }
      ],
      "source": [
        "pattern = r'[Ll][Oo][Vv][Ee][a-zA-Z]*'\n",
        "matches = []\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words containing 'love' variations: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      },
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good. \n",
        "\n",
        "Indica cuántas encontraste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "A8Nf3B_cMlqg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words containing 'so' and 'good' variations: ---------\n",
            "Sooooo\n",
            "soo\n",
            "soooo\n",
            "soo\n",
            "soo\n",
            "goood\n",
            "soo\n",
            "soo\n",
            "soooooo\n",
            "soo\n",
            "soo\n",
            "soooo\n",
            "soo\n",
            "soo\n",
            "\n",
            "\n",
            "--------- Total matches found: 14\n"
          ]
        }
      ],
      "source": [
        "pattern_so = r's[o]{2,}'  \n",
        "pattern_good = r'g[o]{3,}d'\n",
        "matches = []\n",
        "\n",
        "for comment in docs_copy:\n",
        "    found_so = re.findall(pattern_so, comment, re.IGNORECASE)\n",
        "    found_good = re.findall(pattern_good, comment, re.IGNORECASE) \n",
        "    matches.extend(found_so)\n",
        "    matches.extend(found_good)\n",
        "\n",
        "print(\"\\n--------- Words containing 'so' and 'good' variations: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkak1opjMmlk"
      },
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "PYxdp3uhMoD0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words with more than 10 alphabetic characters: ---------\n",
            "recommendation\n",
            "recommended\n",
            "overwhelmed\n",
            "inexpensive\n",
            "establishment\n",
            "imaginative\n",
            "opportunity\n",
            "experiencing\n",
            "underwhelming\n",
            "relationship\n",
            "unsatisfying\n",
            "disappointing\n",
            "outrageously\n",
            "disappointing\n",
            "expectations\n",
            "restaurants\n",
            "suggestions\n",
            "disappointed\n",
            "considering\n",
            "Unfortunately\n",
            "immediately\n",
            "ingredients\n",
            "accommodations\n",
            "maintaining\n",
            "Interesting\n",
            "disrespected\n",
            "accordingly\n",
            "unbelievable\n",
            "cheeseburger\n",
            "descriptions\n",
            "inexpensive\n",
            "disappointed\n",
            "Veggitarian\n",
            "outstanding\n",
            "recommendation\n",
            "disappointed\n",
            "disappointed\n",
            "neighborhood\n",
            "disappointed\n",
            "corporation\n",
            "considering\n",
            "exceptional\n",
            "shawarrrrrrma\n",
            "disappointed\n",
            "vinaigrette\n",
            "immediately\n",
            "unbelievably\n",
            "replenished\n",
            "disappointed\n",
            "enthusiastic\n",
            "Outstanding\n",
            "comfortable\n",
            "interesting\n",
            "INCONSIDERATE\n",
            "considering\n",
            "transcendant\n",
            "disappointment\n",
            "disappointed\n",
            "disappointed\n",
            "overwhelmed\n",
            "professional\n",
            "Furthermore\n",
            "combination\n",
            "connoisseur\n",
            "profiterole\n",
            "outstanding\n",
            "acknowledged\n",
            "ventilation\n",
            "beautifully\n",
            "establishment\n",
            "extraordinary\n",
            "disappointed\n",
            "cheesecurds\n",
            "disappointed\n",
            "interesting\n",
            "experienced\n",
            "opportunity\n",
            "disgraceful\n",
            "restaurants\n",
            "ESTABLISHMENT\n",
            "recommended\n",
            "disappointed\n",
            "recommended\n",
            "acknowledged\n",
            "presentation\n",
            "Philadelphia\n",
            "disappointed\n",
            "disappointing\n",
            "grandmother\n",
            "drastically\n",
            "informative\n",
            "Disappointed\n",
            "constructed\n",
            "comfortable\n",
            "Smashburger\n",
            "cheeseburger\n",
            "neighborhood\n",
            "disappointed\n",
            "hospitality\n",
            "recommending\n",
            "disappointed\n",
            "deliciously\n",
            "compliments\n",
            "recommendation\n",
            "establishment\n",
            "calligraphy\n",
            "traditional\n",
            "combination\n",
            "Unfortunately\n",
            "Wienerschnitzel\n",
            "unfortunately\n",
            "considering\n",
            "highlighted\n",
            "Mediterranean\n",
            "unprofessional\n",
            "anticipated\n",
            "disappointing\n",
            "unexperienced\n",
            "disrespected\n",
            "professional\n",
            "restaurants\n",
            "Disappointing\n",
            "WAAAAAAyyyyyyyyyy\n",
            "reservation\n",
            "imagination\n",
            "undercooked\n",
            "disappointed\n",
            "disappointment\n",
            "disappointment\n",
            "deuchebaggery\n",
            "disappointed\n",
            "disappointment\n",
            "immediately\n",
            "Unfortunately\n",
            "disapppointment\n",
            "circumstances\n",
            "undercooked\n",
            "caterpillar\n",
            "presentation\n",
            "disappointed\n",
            "underwhelming\n",
            "\n",
            "\n",
            "--------- Total matches found: 141\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\b[a-zA-Z]*[a-zA-Z]{11,}[a-zA-Z]*\\b'\n",
        "matches = []\n",
        "\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words with more than 10 alphabetic characters: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApjTNzSxMpDc"
      },
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "Vb0ndRGAMqdL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words starting with uppercase and ending with lowercase (not first word): ---------\n",
            "Loved\n",
            "May\n",
            "Rick\n",
            "Steve\n",
            "Cape\n",
            "Cod\n",
            "This\n",
            "Vegas\n",
            "Burrittos\n",
            "Blah\n",
            "The\n",
            "The\n",
            "They\n",
            "This\n",
            "Mexican\n",
            "Took\n",
            "Luke\n",
            "Our\n",
            "Also\n",
            "Overall\n",
            "Poor\n",
            "Hiro\n",
            "On\n",
            "Frozen\n",
            "The\n",
            "Firehouse\n",
            "My\n",
            "Greek\n",
            "Greek\n",
            "They\n",
            "Loved\n",
            "Heart\n",
            "Attack\n",
            "Grill\n",
            "Vegas\n",
            "The\n",
            "The\n",
            "Great\n",
            "Dos\n",
            "Gringos\n",
            "The\n",
            "Jeff\n",
            "Really\n",
            "It\n",
            "Excalibur\n",
            "Very\n",
            "Bad\n",
            "Customer\n",
            "Service\n",
            "Vegas\n",
            "Rice\n",
            "Company\n",
            "Pho\n",
            "In\n",
            "It\n",
            "Never\n",
            "Hard\n",
            "Rock\n",
            "Casino\n",
            "On\n",
            "Our\n",
            "The\n",
            "Best\n",
            "Buffet\n",
            "Tigerlilly\n",
            "The\n",
            "Yama\n",
            "At\n",
            "Thai\n",
            "Nice\n",
            "Although\n",
            "Indian\n",
            "Worst\n",
            "The\n",
            "We\n",
            "Host\n",
            "Not\n",
            "Phenomenal\n",
            "Definitely\n",
            "Vegas\n",
            "They\n",
            "Delicious\n",
            "Lox\n",
            "Great\n",
            "Subway\n",
            "Subway\n",
            "Vegas\n",
            "He\n",
            "Vegas\n",
            "The\n",
            "The\n",
            "Mandalay\n",
            "Bay\n",
            "Great\n",
            "Voodoo\n",
            "Unfortunately\n",
            "Their\n",
            "Phoenix\n",
            "This\n",
            "Vegas\n",
            "Lordy\n",
            "Khao\n",
            "Soi\n",
            "Perhaps\n",
            "The\n",
            "Not\n",
            "The\n",
            "Love\n",
            "Lemon\n",
            "The\n",
            "Also\n",
            "When\n",
            "Joey\n",
            "Valley\n",
            "Phoenix\n",
            "Magazine\n",
            "Pho\n",
            "Fridays\n",
            "The\n",
            "If\n",
            "For\n",
            "Tasty\n",
            "Jamaican\n",
            "The\n",
            "Lobster\n",
            "Bisque\n",
            "Bussell\n",
            "Sprouts\n",
            "Risotto\n",
            "Filet\n",
            "It\n",
            "Otto\n",
            "As\n",
            "If\n",
            "Ordered\n",
            "Yeah\n",
            "If\n",
            "The\n",
            "Honestly\n",
            "Not\n",
            "Everyone\n",
            "It\n",
            "Also\n",
            "Drinks\n",
            "Seriously\n",
            "Vegas\n",
            "Greek\n",
            "Overall\n",
            "Vegas\n",
            "Good\n",
            "Plus\n",
            "The\n",
            "Thus\n",
            "For\n",
            "Veggitarian\n",
            "Stopped\n",
            "Madison\n",
            "Ironman\n",
            "Jenni\n",
            "Pho\n",
            "Bachi\n",
            "Burger\n",
            "This\n",
            "Pizza\n",
            "Salads\n",
            "They\n",
            "Yelpers\n",
            "The\n",
            "You\n",
            "Bachi\n",
            "Service\n",
            "Will\n",
            "As\n",
            "In\n",
            "English\n",
            "Great\n",
            "By\n",
            "Back\n",
            "And\n",
            "Also\n",
            "They\n",
            "Pizza\n",
            "Hut\n",
            "Both\n",
            "We\n",
            "Seat\n",
            "The\n",
            "Gold\n",
            "Standard\n",
            "Of\n",
            "Thai\n",
            "Tucson\n",
            "Vegas\n",
            "This\n",
            "Chipotle\n",
            "Classy\n",
            "Baseball\n",
            "On\n",
            "Sadly\n",
            "Gordon\n",
            "Ramsey\n",
            "Steak\n",
            "Vegas\n",
            "The\n",
            "Outstanding\n",
            "Best\n",
            "Food\n",
            "Lobster\n",
            "Bisque\n",
            "Vegas\n",
            "The\n",
            "The\n",
            "They\n",
            "Eggplant\n",
            "Green\n",
            "Bean\n",
            "In\n",
            "The\n",
            "Halibut\n",
            "Vegas\n",
            "If\n",
            "Vegas\n",
            "Vegas\n",
            "Crystals\n",
            "Aria\n",
            "To\n",
            "Ians\n",
            "Overall\n",
            "Bouchon\n",
            "Great\n",
            "San\n",
            "Francisco\n",
            "Bay\n",
            "Area\n",
            "Buldogis\n",
            "Gourmet\n",
            "Hot\n",
            "Dog\n",
            "Come\n",
            "For\n",
            "Our\n",
            "On\n",
            "Furthermore\n",
            "Strike\n",
            "Steiners\n",
            "If\n",
            "Anyway\n",
            "Not\n",
            "The\n",
            "The\n",
            "Carly\n",
            "This\n",
            "Love\n",
            "Vegas\n",
            "Very\n",
            "Total\n",
            "Camelback\n",
            "Flower\n",
            "Shop\n",
            "Cartel\n",
            "Coffee\n",
            "Third\n",
            "This\n",
            "Las\n",
            "Vegas\n",
            "This\n",
            "It\n",
            "Worse\n",
            "Bunch\n",
            "Very\n",
            "This\n",
            "Mom\n",
            "Noca\n",
            "Give\n",
            "At\n",
            "Anyway\n",
            "Point\n",
            "Oh\n",
            "Similarly\n",
            "Be\n",
            "The\n",
            "Vegas\n",
            "Sat\n",
            "Sun\n",
            "If\n",
            "Mexican\n",
            "Frenchman\n",
            "Great\n",
            "No\n",
            "Perfect\n",
            "Vegas\n",
            "However\n",
            "Palm\n",
            "The\n",
            "Are\n",
            "This\n",
            "He\n",
            "The\n",
            "As\n",
            "If\n",
            "Thai\n",
            "All\n",
            "My\n",
            "Toast\n",
            "Thai\n",
            "It\n",
            "Phoenix\n",
            "Crema\n",
            "Philadelphia\n",
            "We\n",
            "Good\n",
            "North\n",
            "Scottsdale\n",
            "The\n",
            "Sorry\n",
            "Bloody\n",
            "Mary\n",
            "Despite\n",
            "Pho\n",
            "The\n",
            "Same\n",
            "Caesar\n",
            "After\n",
            "Macarons\n",
            "Our\n",
            "Experience\n",
            "Very\n",
            "Disappointed\n",
            "Big\n",
            "Bay\n",
            "Plater\n",
            "Not\n",
            "Italian\n",
            "That\n",
            "Vegas\n",
            "Baba\n",
            "Ganoush\n",
            "Very\n",
            "The\n",
            "Nobu\n",
            "Smashburger\n",
            "Panna\n",
            "Cotta\n",
            "Very\n",
            "Prices\n",
            "The\n",
            "Good\n",
            "Hawaiian\n",
            "Breeze\n",
            "Mango\n",
            "Magic\n",
            "Pineapple\n",
            "Delight\n",
            "We\n",
            "Needless\n",
            "Anyways\n",
            "The\n",
            "The\n",
            "Strip\n",
            "Steak\n",
            "Paradise\n",
            "Valley\n",
            "Cibo\n",
            "Service\n",
            "That\n",
            "Thumbs\n",
            "Up\n",
            "Italian\n",
            "Pros\n",
            "Large\n",
            "Nice\n",
            "Great\n",
            "The\n",
            "Elk\n",
            "Filet\n",
            "After\n",
            "Cute\n",
            "The\n",
            "Dylan\n",
            "All\n",
            "One\n",
            "Han\n",
            "Nan\n",
            "Chicken\n",
            "As\n",
            "The\n",
            "Bar\n",
            "Edinburgh\n",
            "Chinese\n",
            "Overall\n",
            "Indian\n",
            "Probably\n",
            "Friend\n",
            "Try\n",
            "Chinese\n",
            "When\n",
            "The\n",
            "Level\n",
            "Main\n",
            "When\n",
            "Food\n",
            "Prices\n",
            "The\n",
            "Phoenix\n",
            "It\n",
            "Both\n",
            "Hot\n",
            "Sour\n",
            "Egg\n",
            "Flower\n",
            "Soups\n",
            "Stars\n",
            "Sunday\n",
            "Hunan\n",
            "What\n",
            "The\n",
            "Unfortunately\n",
            "Perfect\n",
            "The\n",
            "The\n",
            "Great\n",
            "Pita\n",
            "Wienerschnitzel\n",
            "Maine\n",
            "Lobster\n",
            "Roll\n",
            "My\n",
            "The\n",
            "Lastly\n",
            "The\n",
            "This\n",
            "Kabuki\n",
            "Best\n",
            "Maria\n",
            "Caballero\n",
            "In\n",
            "To\n",
            "Bad\n",
            "The\n",
            "Wife\n",
            "Went\n",
            "This\n",
            "Hot\n",
            "Everything\n",
            "They\n",
            "For\n",
            "Strip\n",
            "The\n",
            "Costco\n",
            "All\n",
            "To\n",
            "Place\n",
            "Gyros\n",
            "Japanese\n",
            "Now\n",
            "The\n",
            "Albondigas\n",
            "On\n",
            "After\n",
            "No\n",
            "Mediterranean\n",
            "Chicken\n",
            "Salad\n",
            "Mellow\n",
            "Mushroom\n",
            "Thai\n",
            "Vegas\n",
            "Overall\n",
            "Mmmm\n",
            "Buffet\n",
            "Bellagio\n",
            "And\n",
            "My\n",
            "Also\n",
            "Vegas\n",
            "Very\n",
            "How\n",
            "There\n",
            "What\n",
            "Christmas\n",
            "Eve\n",
            "Needless\n",
            "Every\n",
            "However\n",
            "It\n",
            "The\n",
            "Denny\n",
            "If\n",
            "The\n",
            "The\n",
            "The\n",
            "The\n",
            "It\n",
            "Maybe\n",
            "Vegetarian\n",
            "The\n",
            "The\n",
            "Then\n",
            "Insults\n",
            "Taco\n",
            "Unfortunately\n",
            "Your\n",
            "Heimer\n",
            "All\n",
            "Ha\n",
            "Long\n",
            "Bay\n",
            "Subway\n",
            "When\n",
            "Brushfire\n",
            "It\n",
            "Mirage\n",
            "In\n",
            "The\n",
            "Ninja\n",
            "Sushi\n",
            "Then\n",
            "\n",
            "\n",
            "--------- Total matches found: 517\n"
          ]
        }
      ],
      "source": [
        "pattern = r'(?<!^)\\b[A-Z][a-zA-Z]*[a-z]\\b'\n",
        "matches = []\n",
        "\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words starting with uppercase and ending with lowercase (not first word): ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nfm4KhMrNW"
      },
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "id": "OwU-a7eGMsub"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words separated by hyphen without spaces: ---------\n",
            "flat-lined\n",
            "hands-down\n",
            "must-stop\n",
            "sub-par\n",
            "Service-check\n",
            "in-house\n",
            "been-stepped\n",
            "in-and\n",
            "tracked-everywhere\n",
            "multi-grain\n",
            "to-go\n",
            "non-customer\n",
            "High-quality\n",
            "sit-down\n",
            "over-whelm\n",
            "low-key\n",
            "non-fancy\n",
            "golden-crispy\n",
            "over-priced\n",
            "over-hip\n",
            "under-services\n",
            "\n",
            "\n",
            "--------- Total matches found: 21\n"
          ]
        }
      ],
      "source": [
        "pattern = r'\\b[a-zA-Z]+-[a-zA-Z]+\\b'\n",
        "matches = []\n",
        "\n",
        "for comment in docs_copy:\n",
        "    found = re.findall(pattern, comment)\n",
        "    matches.extend(found)\n",
        "\n",
        "print(\"\\n--------- Words separated by hyphen without spaces: ---------\")\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n\\n--------- Total matches found: {len(matches)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEIgl79HMthr"
      },
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\". \n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "id": "I4TSofBMMv9y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------- Words ending in 'ing': ---------\n",
            "during\n",
            "getting\n",
            "being\n",
            "being\n",
            "amazing\n",
            "running\n",
            "redeeming\n",
            "getting\n",
            "thing\n",
            "dressing\n",
            "refreshing\n",
            "running\n",
            "amazing\n",
            "nothing\n",
            "appalling\n",
            "wasting\n",
            "eating\n",
            "going\n",
            "Coming\n",
            "experiencing\n",
            "underwhelming\n",
            "eating\n",
            "raving\n",
            "spring\n",
            "unsatisfying\n",
            "amazing\n",
            "Everything\n",
            "disappointing\n",
            "dining\n",
            "flirting\n",
            "thing\n",
            "coming\n",
            "playing\n",
            "ordering\n",
            "arriving\n",
            "disappointing\n",
            "preparing\n",
            "loving\n",
            "liking\n",
            "reviewing\n",
            "venturing\n",
            "including\n",
            "during\n",
            "changing\n",
            "going\n",
            "considering\n",
            "coming\n",
            "going\n",
            "everything\n",
            "looking\n",
            "dressing\n",
            "dining\n",
            "Everything\n",
            "amazing\n",
            "judging\n",
            "maintaining\n",
            "asking\n",
            "having\n",
            "something\n",
            "lacking\n",
            "Interesting\n",
            "preparing\n",
            "missing\n",
            "feeling\n",
            "exceeding\n",
            "inviting\n",
            "climbing\n",
            "waiting\n",
            "coming\n",
            "being\n",
            "lacking\n",
            "going\n",
            "amazing\n",
            "dealing\n",
            "annoying\n",
            "falling\n",
            "sporting\n",
            "amazing\n",
            "providing\n",
            "building\n",
            "lighting\n",
            "going\n",
            "nothing\n",
            "working\n",
            "eating\n",
            "dressing\n",
            "being\n",
            "outstanding\n",
            "getting\n",
            "amazing\n",
            "rating\n",
            "eating\n",
            "writing\n",
            "everything\n",
            "dining\n",
            "boring\n",
            "charming\n",
            "going\n",
            "making\n",
            "pricing\n",
            "considering\n",
            "amazing\n",
            "Everything\n",
            "nothing\n",
            "nothing\n",
            "driving\n",
            "during\n",
            "evening\n",
            "Outstanding\n",
            "buying\n",
            "handling\n",
            "wasting\n",
            "craving\n",
            "dining\n",
            "interesting\n",
            "amazing\n",
            "being\n",
            "outshining\n",
            "starving\n",
            "coming\n",
            "considering\n",
            "shopping\n",
            "nothing\n",
            "getting\n",
            "trying\n",
            "eating\n",
            "going\n",
            "everything\n",
            "Nothing\n",
            "going\n",
            "outstanding\n",
            "running\n",
            "forgetting\n",
            "upgrading\n",
            "eating\n",
            "bring\n",
            "hoping\n",
            "living\n",
            "dining\n",
            "filling\n",
            "amazing\n",
            "Everything\n",
            "thing\n",
            "amazing\n",
            "Everything\n",
            "interesting\n",
            "amazing\n",
            "amazing\n",
            "waiting\n",
            "going\n",
            "going\n",
            "dining\n",
            "saving\n",
            "something\n",
            "trying\n",
            "disgusting\n",
            "hankering\n",
            "being\n",
            "being\n",
            "being\n",
            "setting\n",
            "sitting\n",
            "waiting\n",
            "satisfying\n",
            "eating\n",
            "being\n",
            "freaking\n",
            "getting\n",
            "amazing\n",
            "disappointing\n",
            "seasoning\n",
            "going\n",
            "being\n",
            "bring\n",
            "letting\n",
            "evening\n",
            "waiting\n",
            "being\n",
            "eating\n",
            "going\n",
            "seating\n",
            "playing\n",
            "amazing\n",
            "staying\n",
            "giving\n",
            "talking\n",
            "amazing\n",
            "amazing\n",
            "amazing\n",
            "amazing\n",
            "filling\n",
            "dripping\n",
            "going\n",
            "serving\n",
            "recommending\n",
            "thing\n",
            "reading\n",
            "seating\n",
            "going\n",
            "everything\n",
            "thing\n",
            "sitting\n",
            "waiting\n",
            "bring\n",
            "revisiting\n",
            "coming\n",
            "anything\n",
            "feeling\n",
            "during\n",
            "thing\n",
            "being\n",
            "amazing\n",
            "being\n",
            "amazing\n",
            "satifying\n",
            "describing\n",
            "coming\n",
            "everything\n",
            "Paying\n",
            "going\n",
            "thing\n",
            "amazing\n",
            "getting\n",
            "cramming\n",
            "considering\n",
            "fucking\n",
            "going\n",
            "appealing\n",
            "getting\n",
            "coming\n",
            "Everything\n",
            "dealing\n",
            "everything\n",
            "something\n",
            "during\n",
            "dining\n",
            "cooking\n",
            "dining\n",
            "editing\n",
            "setting\n",
            "amazing\n",
            "rotating\n",
            "Pricing\n",
            "satisfying\n",
            "disappointing\n",
            "amazing\n",
            "returning\n",
            "running\n",
            "being\n",
            "thing\n",
            "nothing\n",
            "poisoning\n",
            "thinking\n",
            "something\n",
            "going\n",
            "disgusting\n",
            "caring\n",
            "bring\n",
            "Disappointing\n",
            "saying\n",
            "going\n",
            "coming\n",
            "building\n",
            "seating\n",
            "dipping\n",
            "setting\n",
            "anything\n",
            "drinking\n",
            "serving\n",
            "doing\n",
            "putting\n",
            "getting\n",
            "looking\n",
            "coming\n",
            "staying\n",
            "lacking\n",
            "underwhelming\n",
            "drawing\n",
            "bring\n",
            "\n",
            "--------- Total words ending in 'ing': 279\n",
            "\n",
            "--------- Words ending in 'ed': ---------\n",
            "Loved\n",
            "Stopped\n",
            "loved\n",
            "ended\n",
            "overpriced\n",
            "tried\n",
            "disgusted\n",
            "shocked\n",
            "recommended\n",
            "performed\n",
            "red\n",
            "asked\n",
            "overwhelmed\n",
            "grossed\n",
            "melted\n",
            "provided\n",
            "cooked\n",
            "ordered\n",
            "realized\n",
            "Loved\n",
            "lined\n",
            "cooked\n",
            "ripped\n",
            "ripped\n",
            "petrified\n",
            "included\n",
            "expected\n",
            "seasoned\n",
            "cheated\n",
            "walked\n",
            "smelled\n",
            "tailored\n",
            "arrived\n",
            "roasted\n",
            "added\n",
            "cooked\n",
            "passed\n",
            "liked\n",
            "managed\n",
            "served\n",
            "overpriced\n",
            "checked\n",
            "disappointed\n",
            "red\n",
            "decorated\n",
            "served\n",
            "watched\n",
            "greeted\n",
            "seated\n",
            "waited\n",
            "flavored\n",
            "ordered\n",
            "ordered\n",
            "relocated\n",
            "impressed\n",
            "seated\n",
            "priced\n",
            "treated\n",
            "ordered\n",
            "used\n",
            "handed\n",
            "listed\n",
            "missed\n",
            "thrilled\n",
            "inspired\n",
            "desired\n",
            "overcooked\n",
            "decided\n",
            "looked\n",
            "dressed\n",
            "treated\n",
            "ordered\n",
            "sucked\n",
            "expected\n",
            "sucked\n",
            "imagined\n",
            "served\n",
            "arrived\n",
            "satisfied\n",
            "voted\n",
            "insulted\n",
            "disrespected\n",
            "dreamed\n",
            "lived\n",
            "stepped\n",
            "mixed\n",
            "showed\n",
            "realized\n",
            "loved\n",
            "needed\n",
            "loved\n",
            "wrapped\n",
            "uninspired\n",
            "Ordered\n",
            "uploaded\n",
            "covered\n",
            "supposed\n",
            "rolled\n",
            "stayed\n",
            "Based\n",
            "received\n",
            "privileged\n",
            "charged\n",
            "visited\n",
            "proclaimed\n",
            "disappointed\n",
            "Stopped\n",
            "dedicated\n",
            "liked\n",
            "disappointed\n",
            "waited\n",
            "waited\n",
            "burned\n",
            "waited\n",
            "disappointed\n",
            "Waited\n",
            "disappointed\n",
            "pulled\n",
            "prepared\n",
            "fried\n",
            "passed\n",
            "ordered\n",
            "toasted\n",
            "untoasted\n",
            "figured\n",
            "returned\n",
            "eyed\n",
            "disappointed\n",
            "pleased\n",
            "replenished\n",
            "disappointed\n",
            "treated\n",
            "offered\n",
            "tasted\n",
            "dropped\n",
            "decorated\n",
            "served\n",
            "walked\n",
            "stuffed\n",
            "located\n",
            "Cooked\n",
            "disappointed\n",
            "screwed\n",
            "frustrated\n",
            "iced\n",
            "stuffed\n",
            "disappointed\n",
            "grossed\n",
            "enjoyed\n",
            "looked\n",
            "overwhelmed\n",
            "stayed\n",
            "smeared\n",
            "stepped\n",
            "tracked\n",
            "tried\n",
            "rushed\n",
            "loved\n",
            "Ordered\n",
            "cooked\n",
            "insulted\n",
            "contained\n",
            "enjoyed\n",
            "relaxed\n",
            "loved\n",
            "acknowledged\n",
            "trimmed\n",
            "cooked\n",
            "claimed\n",
            "handled\n",
            "asked\n",
            "limited\n",
            "boiled\n",
            "liked\n",
            "sliced\n",
            "attached\n",
            "humiliated\n",
            "fried\n",
            "impressed\n",
            "disappointed\n",
            "priced\n",
            "disappointed\n",
            "need\n",
            "need\n",
            "experienced\n",
            "waited\n",
            "seated\n",
            "decided\n",
            "pleased\n",
            "recommended\n",
            "helped\n",
            "witnessed\n",
            "Waited\n",
            "waited\n",
            "waited\n",
            "checked\n",
            "tasted\n",
            "disappointed\n",
            "served\n",
            "rated\n",
            "recommended\n",
            "pulled\n",
            "waited\n",
            "acknowledged\n",
            "perpared\n",
            "dusted\n",
            "powdered\n",
            "enjoyed\n",
            "expanded\n",
            "ended\n",
            "arrived\n",
            "wanted\n",
            "disappointed\n",
            "need\n",
            "checked\n",
            "impressed\n",
            "reheated\n",
            "tasted\n",
            "grilled\n",
            "focused\n",
            "roasted\n",
            "asked\n",
            "ignored\n",
            "tasted\n",
            "Ordered\n",
            "greeted\n",
            "seated\n",
            "Tried\n",
            "seated\n",
            "Disappointed\n",
            "ordered\n",
            "constructed\n",
            "fried\n",
            "requested\n",
            "used\n",
            "tasted\n",
            "drenched\n",
            "tried\n",
            "walked\n",
            "expected\n",
            "disappointed\n",
            "mortified\n",
            "impressed\n",
            "refrained\n",
            "pleased\n",
            "loved\n",
            "grilled\n",
            "reminded\n",
            "sucked\n",
            "hooked\n",
            "ordered\n",
            "disappointed\n",
            "seasoned\n",
            "added\n",
            "touched\n",
            "fried\n",
            "opened\n",
            "impressed\n",
            "watched\n",
            "Tasted\n",
            "ordered\n",
            "received\n",
            "impressed\n",
            "overcooked\n",
            "cooked\n",
            "needed\n",
            "served\n",
            "ordered\n",
            "overpriced\n",
            "packed\n",
            "opposed\n",
            "priced\n",
            "surprised\n",
            "focused\n",
            "overpriced\n",
            "tried\n",
            "enjoyed\n",
            "qualified\n",
            "tasted\n",
            "hated\n",
            "watched\n",
            "fried\n",
            "tried\n",
            "helped\n",
            "started\n",
            "highlighted\n",
            "used\n",
            "enjoyed\n",
            "ordered\n",
            "tasted\n",
            "asked\n",
            "refused\n",
            "tried\n",
            "toasted\n",
            "anticipated\n",
            "unexperienced\n",
            "insulted\n",
            "disrespected\n",
            "impressed\n",
            "puréed\n",
            "asked\n",
            "rated\n",
            "lacked\n",
            "sliced\n",
            "pulled\n",
            "undercooked\n",
            "seemed\n",
            "watered\n",
            "lacked\n",
            "disappointed\n",
            "overpriced\n",
            "ensued\n",
            "disappointed\n",
            "placed\n",
            "avoided\n",
            "received\n",
            "wanted\n",
            "sucked\n",
            "happened\n",
            "owned\n",
            "wanted\n",
            "Overpriced\n",
            "vomited\n",
            "started\n",
            "unwrapped\n",
            "lacked\n",
            "seemed\n",
            "undercooked\n",
            "closed\n",
            "refried\n",
            "dried\n",
            "disappointed\n",
            "impressed\n",
            "wasted\n",
            "poured\n",
            "\n",
            "--------- Total words ending in 'ed': 335\n"
          ]
        }
      ],
      "source": [
        "pattern_ing = r'\\b\\w+ing\\b'\n",
        "pattern_ed = r'\\b\\w+ed\\b'\n",
        "matches_ing = []\n",
        "matches_ed = []\n",
        "\n",
        "for comment in docs_copy:\n",
        "    found_ing = re.findall(pattern_ing, comment)\n",
        "    found_ed = re.findall(pattern_ed, comment)\n",
        "    matches_ing.extend(found_ing)\n",
        "    matches_ed.extend(found_ed)\n",
        "\n",
        "print(\"\\n--------- Words ending in 'ing': ---------\")\n",
        "for match in matches_ing:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n--------- Total words ending in 'ing': {len(matches_ing)}\")\n",
        "\n",
        "print(\"\\n--------- Words ending in 'ed': ---------\") \n",
        "for match in matches_ed:\n",
        "    print(match)\n",
        "    \n",
        "print(f\"\\n--------- Total words ending in 'ed': {len(matches_ed)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70StdqAZa9E9"
      },
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaDUFXHrMvX2"
      },
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "id": "K3kQzPOPMx0w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['wow loved this place',\n",
              " 'crust is not good',\n",
              " 'not tasty and the texture was just nasty',\n",
              " 'stopped by during the late may bank holiday off rick steve recommendation and loved it',\n",
              " 'the selection on the menu was great and so were the prices',\n",
              " 'now i am getting angry and i want my damn pho',\n",
              " 'honeslty it didnt taste that fresh',\n",
              " 'the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer',\n",
              " 'the fries were great too',\n",
              " 'a great touch']"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_docs = []\n",
        "\n",
        "for doc in docs_copy:\n",
        "    # Convert to lowercase\n",
        "    doc = doc.lower()\n",
        "    \n",
        "    # Remove all non-alphabetic characters (keep spaces)\n",
        "    doc = re.sub(r'[^a-z\\s]', '', doc)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    doc = ' '.join(doc.split())\n",
        "    \n",
        "    cleaned_docs.append(doc)\n",
        "\n",
        "# Print first 10 cleaned comments\n",
        "cleaned_docs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZwEhg2lUSAX"
      },
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus. \n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "kbAL9-v0V-jx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens in corpus: 10777\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['wow', 'loved', 'this', 'place'],\n",
              " ['crust', 'is', 'not', 'good'],\n",
              " ['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty'],\n",
              " ['stopped',\n",
              "  'by',\n",
              "  'during',\n",
              "  'the',\n",
              "  'late',\n",
              "  'may',\n",
              "  'bank',\n",
              "  'holiday',\n",
              "  'off',\n",
              "  'rick',\n",
              "  'steve',\n",
              "  'recommendation',\n",
              "  'and',\n",
              "  'loved',\n",
              "  'it'],\n",
              " ['the',\n",
              "  'selection',\n",
              "  'on',\n",
              "  'the',\n",
              "  'menu',\n",
              "  'was',\n",
              "  'great',\n",
              "  'and',\n",
              "  'so',\n",
              "  'were',\n",
              "  'the',\n",
              "  'prices'],\n",
              " ['now',\n",
              "  'i',\n",
              "  'am',\n",
              "  'getting',\n",
              "  'angry',\n",
              "  'and',\n",
              "  'i',\n",
              "  'want',\n",
              "  'my',\n",
              "  'damn',\n",
              "  'pho'],\n",
              " ['honeslty', 'it', 'didnt', 'taste', 'that', 'fresh'],\n",
              " ['the',\n",
              "  'potatoes',\n",
              "  'were',\n",
              "  'like',\n",
              "  'rubber',\n",
              "  'and',\n",
              "  'you',\n",
              "  'could',\n",
              "  'tell',\n",
              "  'they',\n",
              "  'had',\n",
              "  'been',\n",
              "  'made',\n",
              "  'up',\n",
              "  'ahead',\n",
              "  'of',\n",
              "  'time',\n",
              "  'being',\n",
              "  'kept',\n",
              "  'under',\n",
              "  'a',\n",
              "  'warmer'],\n",
              " ['the', 'fries', 'were', 'great', 'too'],\n",
              " ['a', 'great', 'touch']]"
            ]
          },
          "execution_count": 441,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize each cleaned document into words\n",
        "tokenized_docs = [doc.split() for doc in cleaned_docs]\n",
        "\n",
        "# Calculate total number of tokens\n",
        "total_tokens = sum(len(doc) for doc in tokenized_docs)\n",
        "\n",
        "print(f\"Total number of tokens in corpus: {total_tokens}\")\n",
        "\n",
        "# Show first 10 tokenized documents\n",
        "tokenized_docs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      },
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus. \n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total tokens after removing stopwords: 5776\n",
            "Number of unique tokens in vocabulary: 1941\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['wow', 'loved', 'place'],\n",
              " ['crust', 'not', 'good'],\n",
              " ['not', 'tasty', 'texture', 'nasty'],\n",
              " ['stopped',\n",
              "  'late',\n",
              "  'may',\n",
              "  'bank',\n",
              "  'holiday',\n",
              "  'off',\n",
              "  'rick',\n",
              "  'steve',\n",
              "  'recommendation',\n",
              "  'loved'],\n",
              " ['selection', 'menu', 'great', 'prices'],\n",
              " ['getting', 'angry', 'want', 'damn', 'pho'],\n",
              " ['honeslty', 'didnt', 'taste', 'fresh'],\n",
              " ['potatoes',\n",
              "  'like',\n",
              "  'rubber',\n",
              "  'could',\n",
              "  'tell',\n",
              "  'made',\n",
              "  'ahead',\n",
              "  'time',\n",
              "  'kept',\n",
              "  'warmer'],\n",
              " ['fries', 'great'],\n",
              " ['great', 'touch']]"
            ]
          },
          "execution_count": 442,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']\n",
        "\n",
        "# Remove stopwords from tokenized documents\n",
        "filtered_docs = [[word for word in doc if word not in mis_stopwords] for doc in tokenized_docs]\n",
        "\n",
        "# Calculate total tokens after removing stopwords\n",
        "total_tokens_filtered = sum(len(doc) for doc in filtered_docs)\n",
        "print(f\"Total tokens after removing stopwords: {total_tokens_filtered}\")\n",
        "\n",
        "# Calculate unique tokens (vocabulary)\n",
        "unique_tokens = set(word for doc in filtered_docs for word in doc)\n",
        "print(f\"Number of unique tokens in vocabulary: {len(unique_tokens)}\")\n",
        "\n",
        "# Show first 10 filtered documents\n",
        "filtered_docs[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDbKkuxRbLoX"
      },
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7fzbvqVbUGr"
      },
      "source": [
        "<< incluye aquí tus comentarios >>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      },
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "759SG4TyfbUn",
        "Zj-h4drXD-X9",
        "BY6yifxscfrx",
        "k_ewoagic5jc",
        "70StdqAZa9E9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "master-ai-tec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
